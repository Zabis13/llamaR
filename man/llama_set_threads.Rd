% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llama.R
\name{llama_set_threads}
\alias{llama_set_threads}
\title{Set the number of threads for a context}
\usage{
llama_set_threads(ctx, n_threads, n_threads_batch = n_threads)
}
\arguments{
\item{ctx}{Context handle returned by [llama_new_context]}

\item{n_threads}{Number of threads for single-token generation}

\item{n_threads_batch}{Number of threads for batch processing (prompt encoding).
Defaults to the same value as \code{n_threads}.}
}
\value{
No return value, called for side effects.
}
\description{
Set the number of threads for a context
}
\examples{
\dontrun{
model <- llama_load_model("model.gguf")
ctx <- llama_new_context(model)
llama_set_threads(ctx, n_threads = 8L)
}
}
