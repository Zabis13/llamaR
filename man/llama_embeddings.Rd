% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llama.R
\name{llama_embeddings}
\alias{llama_embeddings}
\title{Extract embeddings for a text}
\usage{
llama_embeddings(ctx, text)
}
\arguments{
\item{ctx}{Context handle returned by [llama_new_context]}

\item{text}{Character string to embed}
}
\value{
A numeric vector of length \code{n_embd} (the model's embedding
  dimension) containing the hidden-state representation of the input text.
}
\description{
Runs the model in embeddings mode and returns the hidden-state vector
of the last token. Note: meaningful only for models that support embeddings.
}
\examples{
if (FALSE) {
model <- llama_load_model("model.gguf")
ctx <- llama_new_context(model)

emb1 <- llama_embeddings(ctx, "Hello world")
emb2 <- llama_embeddings(ctx, "Hi there")

# Cosine similarity
similarity <- sum(emb1 * emb2) / (sqrt(sum(emb1^2)) * sqrt(sum(emb2^2)))
cat("Similarity:", similarity, "\n")
}
}
