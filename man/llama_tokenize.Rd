% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llama.R
\name{llama_tokenize}
\alias{llama_tokenize}
\title{Tokenize text into token IDs}
\usage{
llama_tokenize(ctx, text, add_special = TRUE)
}
\arguments{
\item{ctx}{Context handle returned by [llama_new_context]}

\item{text}{Character string to tokenize}

\item{add_special}{Whether to add special tokens (BOS/EOS) as configured by the model}
}
\value{
Integer vector of token IDs
}
\description{
Tokenize text into token IDs
}
\examples{
\dontrun{
model <- llama_load_model("model.gguf")
ctx <- llama_new_context(model)

tokens <- llama_tokenize(ctx, "Hello, world!")
print(tokens)
# [1] 1 15043 29892 3186 29991

# Without special tokens
tokens <- llama_tokenize(ctx, "Hello", add_special = FALSE)
}
}
