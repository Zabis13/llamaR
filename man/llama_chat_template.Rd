% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llama.R
\name{llama_chat_template}
\alias{llama_chat_template}
\title{Get model's built-in chat template}
\usage{
llama_chat_template(model, name = NULL)
}
\arguments{
\item{model}{Model handle returned by [llama_load_model]}

\item{name}{Optional template name (NULL for default)}
}
\value{
Character string with the template, or NULL if not available
}
\description{
Returns the chat template string embedded in the model file, if any.
Common templates include ChatML, Llama, Mistral, etc.
}
\examples{
\dontrun{
model <- llama_load_model("llama-3.2-instruct.gguf")
tmpl <- llama_chat_template(model)
cat(tmpl)
}
}
