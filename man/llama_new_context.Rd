% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llama.R
\name{llama_new_context}
\alias{llama_new_context}
\title{Create an inference context}
\usage{
llama_new_context(model, n_ctx = 2048L, n_threads = 4L)
}
\arguments{
\item{model}{Model handle returned by [llama_load_model]}

\item{n_ctx}{Context window size (number of tokens). 0 means use the model's trained value.}

\item{n_threads}{Number of CPU threads to use}
}
\value{
An external pointer (class \code{externalptr}) wrapping the inference
  context. This handle is required by generation, tokenization, and embedding
  functions. Freed automatically by the garbage collector or manually via
  \code{\link{llama_free_context}}.
}
\description{
Create an inference context
}
\examples{
if (FALSE) {
model <- llama_load_model("model.gguf")
ctx <- llama_new_context(model, n_ctx = 4096L, n_threads = 8L)
# ... use context for generation ...
llama_free_context(ctx)
llama_free_model(model)
}
}
