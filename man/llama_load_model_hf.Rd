% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hf.R
\name{llama_load_model_hf}
\alias{llama_load_model_hf}
\title{Load a model directly from Hugging Face}
\usage{
llama_load_model_hf(repo_id, ..., n_gpu_layers = 0L)
}
\arguments{
\item{repo_id}{Character. Hugging Face repository in \code{"org/repo"} format.}

\item{...}{Additional arguments passed to \code{\link{llama_hf_download}}
(e.g. \code{pattern}, \code{cache_dir}, \code{force}).}

\item{n_gpu_layers}{Integer. Number of layers to offload to GPU.
Use \code{-1L} for all layers. Defaults to \code{0L} (CPU only).}
}
\value{
An external pointer to the loaded model, as returned by
  \code{\link{llama_load_model}}.
}
\description{
Convenience function that downloads a GGUF model from Hugging Face (if not
already cached) and loads it via \code{\link{llama_load_model}}.
}
\examples{
\dontrun{
model <- llama_load_model_hf("TheBloke/Llama-2-7B-GGUF",
                              pattern = "*q2_k*")
}
}
