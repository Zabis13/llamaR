% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llama.R
\name{llama_batch_init}
\alias{llama_batch_init}
\title{Initialise a llama batch}
\usage{
llama_batch_init(n_tokens, embd = 0L, n_seq_max = 1L)
}
\arguments{
\item{n_tokens}{Maximum number of tokens in the batch.}

\item{embd}{Embedding size; 0 means token-ID mode (normal inference).}

\item{n_seq_max}{Maximum number of sequences per token.}
}
\value{
An external pointer to the allocated batch.
}
\description{
Allocates a \code{llama_batch} that can hold up to \code{n_tokens} tokens.
Use \code{llama_batch_free()} to release the memory when done.
}
\examples{
\dontrun{
batch <- llama_batch_init(512L)
llama_batch_free(batch)
}
}
