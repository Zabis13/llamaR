% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llama.R
\name{llama_lora_load}
\alias{llama_lora_load}
\title{Load a LoRA adapter}
\usage{
llama_lora_load(model, path)
}
\arguments{
\item{model}{Model handle returned by [llama_load_model]}

\item{path}{Path to the LoRA adapter file (.gguf or .bin)}
}
\value{
An external pointer (class \code{externalptr}) wrapping the loaded
  LoRA (Low-Rank Adaptation) adapter. Pass this handle to
  \code{\link{llama_lora_apply}} to activate the adapter.
}
\description{
Loads a LoRA (Low-Rank Adaptation) adapter file that can be applied
to modify the model's behavior without changing the base weights.
}
\examples{
if (FALSE) {
model <- llama_load_model("base-model.gguf")
lora <- llama_lora_load(model, "fine-tuned-adapter.gguf")

ctx <- llama_new_context(model)
llama_lora_apply(ctx, lora, scale = 1.0)

# Now generation uses the LoRA-modified model
result <- llama_generate(ctx, "Hello")
}
}
